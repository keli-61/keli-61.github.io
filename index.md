---
layout: default
---

## Bio
I am a Principal Researcher and Team Manager at [Tencent Youtu Lab](https://open.youtu.qq.com/#/open). My research interests lie in the area of deep learning and its application in computer vision and natural language processing. Before joining Tencent, I received my M.S. degree from Xiamen University in 2018 under the supervision of [*Prof. Rongrong Ji*](https://mac.xmu.edu.cn/rrji_en/). I received my B.S. degree from Zhengzhou University in 2015, advised by [*Prof. Mingliang Xu*](https://scholar.google.com.hk/citations?user=u-8x34cAAAAJ&hl=zh-CN).


## Activities

*   Reviewer for ICML, ICLR, NeurIPS, CVPR, ICCV, ECCV, AAAI and TPAMI.


## Selected Publications

Below are some of the works that represent my main research interests. Full paper list (including preprints) could be found at [Google Scholar](https://scholar.google.com/citations?user=mfWsFM0AAAAJ&hl=en).

(* denotes corresponding author)

| **Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models**<br />Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, **Ke Li**, Xing Sun.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2025.<br />[Paper](https://arxiv.org/abs/2506.01413), [Code](https://github.com/yuleiqin/RAIF)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/yuleiqin/RAIF.svg" alt="GitHub stars" title="" /> |
| **VITA-Audio: Fast Interleaved Audio-Text Token Generation for Efficient Large Speech-Language Model**<br />Zuwei Long, Yunhang Shen, Chaoyou Fu, Heting Gao, lijiang Li, Peixian Chen, Mengdan Zhang, Hang Shao, Jian Li, Jinlong Peng, Haoyu Cao, **Ke Li**, Rongrong Ji, Xing Sun.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2025.<br />[Paper](https://arxiv.org/pdf/2505.03739), [Code](https://github.com/VITA-MLLM/VITA-Audio)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/VITA-MLLM/VITA-Audio.svg" alt="GitHub stars" title="" /> |
| **VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction**<br />Chaoyou Fu, Haojia Lin, Xiong Wang, YiFan Zhang, Yunhang Shen, Xiaoyu Liu, Haoyu Cao, Zuwei Long, Heting Gao, **Ke Li**, Long MA, Xiawu Zheng, Rongrong Ji, Xing Sun, Caifeng Shan, Ran He.<br />Advances in Neural Information Processing Systems (**NeurIPS, spotlight**), 2025.<br />[Paper](https://arxiv.org/abs/2501.01957), [Code](https://github.com/VITA-MLLM/VITA)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/VITA-MLLM/VITA.svg" alt="GitHub stars" title="" /> |
| **MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models**<br />Chaoyou Fu, Peixian Chen, Yunhang Shen, Yulei Qin, Mengdan Zhang, Xu Lin, Jinrui Yang, Xiawu Zheng, **Ke Li\***, Xing Sun, Rongrong Ji.<br />Advances in Neural Information Processing Systems (**NeurIPS, spotlight**)<br />[Paper](https://arxiv.org/abs/2306.13394), [Code](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg" alt="GitHub stars" title="" /> |
| **LTD-Bench: Evaluating Large Language Models by Letting Them Draw**<br />Liuhao Lin, **Ke Li\***, Zihan Xu, Yuchen Shi, Yulei Qin, Yan Zhang, Xing Sun, Rongrong Ji.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2025.<br />[Paper](https://neurips.cc/virtual/2025/poster/121630), [Code](https://github.com/walktaster/LTD-Bench)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/walktaster/LTD-Bench.svg" alt="GitHub stars" title="" /> |
| **Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM**<br />Xiong Wang, Yangze Li, Chaoyou Fu, Yike Zhang, Yunhang Shen, Lei Xie, **Ke Li**, Xing Sun, Long MA.<br />International Conference on Machine Learning (**ICML**), 2025<br />[Paper](https://arxiv.org/abs/2411.00774), [Code](https://github.com/VITA-MLLM/Freeze-Omni)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/VITA-MLLM/Freeze-Omni.svg" alt="GitHub stars" title="" /> |
| **Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis**<br />Chaoyou Fu, Yuhan Dai, Yongdong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou, Yunhang Shen, Mengdan Zhang, Peixian Chen, Yanwei Li, Shaohui Lin, Sirui Zhao, **Ke Li**, Tong Xu, Xiawu Zheng, Enhong Chen, Caifeng Shan, Ran He, Xing Sun.<br />Computer Vision and Pattern Recognition (**CVPR, highlight**), 2025<br />[Paper](https://arxiv.org/abs/2405.21075), [Code](https://github.com/MME-Benchmarks/Video-MME)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/MME-Benchmarks/Video-MME.svg" alt="GitHub stars" title="" /> |
| **Distilling Spatially-Heterogeneous Distortion Perception for Blind Image Quality Assessment**<br />Xudong Li, Wenjie Nie, Yan Zhang, Runze Hu, **Ke Li**, Xiawu Zheng, Liujuan Cao.<br />Computer Vision and Pattern Recognition (**CVPR**), 2025<br />[Paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Distilling_Spatially-Heterogeneous_Distortion_Perception_for_Blind_Image_Quality_Assessment_CVPR_2025_paper.pdf) |
| **FlashSloth: Lightning Multimodal Large Language Models via Embedded Visual Compression**<br />Bo Tong, Bokai Lai, Yiyi Zhou, Gen Luo, Yunhang Shen, **Ke Li**, Xiaoshuai Sun, Rongrong Ji.<br />Computer Vision and Pattern Recognition (**CVPR**), 2025<br />[Paper](https://arxiv.org/abs/2412.04317), [Code](https://github.com/codefanw/FlashSloth)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/codefanw/FlashSloth.svg" alt="GitHub stars" title="" /> |
| **Few-Shot Image Quality Assessment via Adaptation of Vision-Language Models**<br />Xudong Li, Zihao Huang, Yan Zhang, Yunhang Shen, **Ke Li**, Xiawu Zheng, Liujuan Cao, Rongrong Ji.<br />International Conference on Computer Vision (**ICCV**), 2025<br />[Paper](https://arxiv.org/abs/2409.05381), [Code](https://github.com/LXDxmu/GRMP-IQA)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/LXDxmu/GRMP-IQA.svg" alt="GitHub stars" title="" /> |
| **PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**<br />Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, **Ke Li**, Peng Zhai, Lihua Zhang.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2024.<br />[Paper](https://arxiv.org/abs/2405.19266), [Code](https://github.com/ydk122024/PediatricsGPT)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/ydk122024/PediatricsGPT.svg" alt="GitHub stars" title="" /> |
| **Align before Collaborate: Mitigating Feature Misalignment for Robust Multi-Agent Perception**<br />Kun Yang, Dingkang Yang, **Ke Li**, Dongling Xiao, Zedian Shao, Peng Sun, Liang Song.<br />European Conference on Computer Vision (**ECCV, Oral**), 2024<br />[Paper](https://keli.info) |
| **Towards Multimodal Sentiment Analysis Debiasing via Bias Purification**<br />Dingkang Yang, Mingcheng Li, Dongling Xiao, Yang Liu, Kun Yang, Zhaoyu Chen, Yuzheng Wang, Peng Zhai, **Ke Li**, Lihua Zhang.<br />European Conference on Computer Vision (**ECCV**), 2024<br />[Paper](https://arxiv.org/abs/2403.05023) |
| **Integrating Global Context Contrast and Local Sensitivity for Blind Image Quality Assessment**<br />XuDong Li, Runze Hu, Jingyuan Zheng, Yan Zhang, Shengchuan Zhang, Xiawu Zheng, **Ke Li**, Yunhang Shen, Yutao Liu, Pingyang Dai, Rongrong Ji.<br />International Conference on Machine Learning (**ICML, spotlight**), 2024<br />[Paper](https://openreview.net/pdf?id=MRYS3Zb4iV) |
| **Adaptive Feature Selection for No-Reference Image Quality Assessment by Mitigating Semantic Noise Sensitivity**<br />Xudong Li, Timin Gao, Runze Hu, Yan Zhang, Shengchuan Zhang, Xiawu Zheng, Jingyuan Zheng, Yunhang Shen, **Ke Li**, Yutao Liu, Pingyang Dai, Rongrong Ji.<br />International Conference on Machine Learning (**ICML**), 2024<br />[Paper](https://arxiv.org/abs/2312.06158) |
| **Training-free Transformer Architecture Search with Zero-cost Proxy Guided Evolution**<br />Qinqin Zhou, Kekai Sheng, Xiawu Zheng, **Ke Li**, Yonghong Tian, Jie Chen, Rongrong Ji.<br />IEEE Transactions on Pattern Analysis and Machine Intelligence (**TPAMI**), 2024.<br />[Paper](https://ieeexplore.ieee.org/document/10475573), [Code](https://github.com/decemberzhou/TF_TAS)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/decemberzhou/TF_TAS.svg" alt="GitHub stars" title="" /> |
| **Sinkhorn Distance Minimization for Knowledge Distillation**<br />Xiao Cui, Yulei Qin, Yuting Gao, Enwei Zhang, Zihan Xu, Tong Wu, **Ke Li**, Xing Sun, Wengang Zhou, Houqiang Li.<br />International Conference on Computational Linguistics (**COLING**), 2024<br />[Paper](https://arxiv.org/abs/2402.17110) |
| **Aligning and Prompting Everything All at Once for Universal Visual Perception**<br />Yunhang Shen, Chaoyou Fu, Peixian Chen, Mengdan Zhang, **Ke Li**, Xing Sun, Yunsheng Wu, Shaohui Lin, Rongrong Ji.<br />Computer Vision and Pattern Recognition (**CVPR**), 2024<br />[Paper](https://arxiv.org/abs/2312.02153), [Code](https://github.com/shenyunhang/APE)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/shenyunhang/APE.svg" alt="GitHub stars" title="" /> |
| **A General and Efficient Training for Transformer via Token Expansion**<br />Wenxuan Huang, Yunhang Shen, Jiao Xie, Baochang Zhang, Gaoqi He, **Ke Li**, Xing Sun, Shaohui Lin.<br />Computer Vision and Pattern Recognition (**CVPR**), 2024<br />[Paper](https://keli.info/) |
| **Solving the Catastrophic Forgetting Problem in Generalized Category Discovery**<br />Xinzi Cao, Xiawu Zheng, Guanhong Wang, Weijiang Yu, Yunhang Shen, **Ke Li**, Yutong Lu, Yonghong Tian.<br />Computer Vision and Pattern Recognition (**CVPR**), 2024<br />[Paper](https://keli.info/) |
| **Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental Learning**<br />Xialei Liu, Jiang-Tian Zhai, Andrew D. Bagdanov, **Ke Li**, Ming-Ming Cheng.<br />Computer Vision and Pattern Recognition (**CVPR**), 2024<br />[Paper](https://keli.info/) |
| **Weakly Supervised Open-Vocabulary Object Detection**<br />Jianghang Lin, Yunhang Shen, Bingquan Wang, Shaohui Lin, **Ke Li**, Liujuan Cao.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2024<br />[Paper](https://arxiv.org/abs/2312.12437) |
| **SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric Positive Definite Space**<br />Yunchen Li, Zhou Yu, Gaoqi He, Yunhang Shen, **Ke Li**, Xing Sun, Shaohui Lin.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2024<br />[Paper](https://arxiv.org/abs/2312.08200) |
| **Semi-Supervised Blind Image Quality Assessment through Knowledge Distillation and Incremental Learning**<br />Wensheng Pan, Timin Gao, Yan Zhang, Xiawu Zheng, Yunhang Shen, **Ke Li**, Runze Hu, Yutao Liu, Pingyang Dai.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2024<br />[Paper](https://keli.info/) |
| **SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger**<br />Yuting Gao, Jinfeng Liu, Zihan Xu, Tong Wu, Enwei Zhang, **Ke Li**, Jie Yang, Wei Liu, Xing Sun.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2024<br />[Paper](https://arxiv.org/abs/2303.17561) |
| **CAPro: Webly Supervised Learning with Cross-modality Aligned Prototypes**<br />Yulei Qin, Xingyu Chen, Yunhang Shen, Chaoyou Fu, Yun Gu, **Ke Li**, Xing Sun, Rongrong Ji.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2023.<br />[Paper](http://keli.info), [Code](https://github.com/yuleiqin/capro)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/yuleiqin/capro.svg" alt="GitHub stars" title="" /> |
| **Multi-modal Queried Object Detection in the Wild**<br />Yifan Xu, Mengdan Zhang, Chaoyou Fu, Peixian Chen, Xiaoshan Yang, **Ke Li**, Changsheng Xu.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2023.<br />[Paper](https://arxiv.org/abs/2305.18980), [Code](https://github.com/YifanXu74/MQ-Det)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/YifanXu74/MQ-Det.svg" alt="GitHub stars" title="" /> |
| **LocLoc: Low-level Cues and Local-area Guides for Weakly Supervised Object Localization**<br />Xinzi Cao, Xiawu Zheng, Yunhang Shen, **Ke Li**, Jie Chen, Yutong Lu, Yonghong Tian.<br />ACM International Conference on Multimedia (**ACM MM**), 2023.<br />[Paper](http://keli.info) |
| **Masked Autoencoders are Efficient Class Incremental Learners**<br />Jiang-Tian Zhai, Xialei Liu, Andy Bagdanov, **Ke Li**, Ming-Ming Cheng.<br />International Conference on Computer Vision (**ICCV**), 2023.<br />[Paper](https://arxiv.org/abs/2308.12510), [Code](https://github.com/scok30/MAE-CIL)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/scok30/MAE-CIL.svg" alt="GitHub stars" title="" /> |
| **Woodpecker: Hallucination Correction for Multimodal Large Language Models**<br />Shukang Yin, Chaoyou Fu, Sirui Zhao, Tong Xu, Hao Wang, Dianbo Sui, Yunhang Shen, **Ke Li**, Xing Sun, Enhong Chen.<br />arxiv, 2023<br />[Paper](https://arxiv.org/abs/2310.16045), [Code](https://github.com/BradyFU/Woodpecker)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/BradyFU/Woodpecker.svg" alt="GitHub stars" title="" /> |
| **A Survey on Multimodal Large Language Models**<br />Shukang Yin , Chaoyou Fu, Sirui Zhao, **Ke Li**, Xing Sun, Tong Xu, Enhong Chen.<br />arxiv, 2023<br />[Paper](https://arxiv.org/abs/2306.13549), [Code](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg" alt="GitHub stars" title="" /> |
| **CF-ViT: A General Coarse-to-Fine Method for Vision Transformer**<br />Mengzhao Chen, Mingbao Lin, **Ke Li**, Yunhang Shen, Yongjian Wu, Fei Chao, Rongrong Ji.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI, Oral**), 2023<br />[Paper](https://arxiv.org/abs/2203.03821), [Code](https://github.com/ChenMnZ/CF-ViT)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/ChenMnZ/CF-ViT.svg" alt="GitHub stars" title="" /> |
| **Adaptive Hierarchy-Branch Fusion for Online Knowledge Distillation**<br />Linrui Gong, Shaohui Lin, Baochang Zhang, Yunhang Shen, **Ke Li**, Ruizhi Qiao, Bo Ren, Muqing Li, Zhou Yu, Lizhuang Ma.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2023<br />[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/25937) |
| **PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining**<br />Yuting Gao, Jinfeng Liu, Zihan Xu, Jun Zhang, **Ke Li**, Rongrong Ji, Chunhua Shen.<br />Advances in Neural Information Processing Systems (**NeurIPS, Oral**), 2022<br />[Paper](https://arxiv.org/abs/2204.14095), [Code](https://github.com/Yuting-Gao/PyramidCLIP)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/Yuting-Gao/PyramidCLIP.svg" alt="GitHub stars" title="" />|
| **Learning Best Combination for Efficient N:M Sparsity**<br />Yuxin Zhang, Mingbao Lin, Zhihang Lin, Yiting Luo, **Ke Li**, Fei Chao, Yongjian Wu, Rongrong Ji.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2022<br />[Paper](https://arxiv.org/abs/2206.06662), [Code](https://github.com/zyxxmu/LBC)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/zyxxmu/LBC.svg" alt="GitHub stars" title="" /> |
| **Fine-grained Data Distribution Alignment for Post-Training Quantization**<br />Yunshan Zhong, Mingbao Lin, Mengzhao Chen, **Ke Li**, Yunhang Shen, Fei Chao, Yongjian Wu, Rongrong Ji.<br />European Conference on Computer Vision (**ECCV**), 2022<br />[Paper](https://arxiv.org/abs/2109.04186), [Code](https://github.com/zysxmu/FDDA)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/zysxmu/FDDA.svg" alt="GitHub stars" title="" />|
| **Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution Networks**<br />Yunshan Zhong, Mingbao Lin, Xunchao Li, **Ke Li**, Yunhang Shen, Fei Chao, Yongjian Wu, Rongrong Ji.<br />European Conference on Computer Vision (**ECCV**), 2022<br />[Paper](https://arxiv.org/abs/2203.03844), [Code](https://github.com/zysxmu/DDTB)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/zysxmu/DDTB.svg" alt="GitHub stars" title="" /> |
| **Long-Tailed Class Incremental Learning**<br />Xialei Liu, Yusong Hu, Xu-Sheng Cao, Andy Bagdanov, **Ke Li**, Ming-Ming Cheng.<br />European Conference on Computer Vision (**ECCV**), 2022<br />[Paper](https://arxiv.org/abs/2210.00266), [Code](https://github.com/xialeiliu/Long-Tailed-CIL)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/xialeiliu/Long-Tailed-CIL.svg" alt="GitHub stars" title="" /> |
| **DisCo: Remedying Self-supervised Learning on Lightweight Models with Distilled Contrastive Learning**<br />Yuting Gao, Jia-Xin Zhuang, Shaohui Lin, Hao Cheng, Xing Sun, **Ke Li\***, Chunhua Shen.<br />European Conference on Computer Vision (**ECCV, Oral**), 2022<br />[Paper](https://arxiv.org/abs/2104.09124), [Code](https://github.com/Yuting-Gao/DisCo-pytorch)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/Yuting-Gao/DisCo-pytorch.svg" alt="GitHub stars" title="" /> |
| **Efficient Decoder-free Object Detection with Transformers**<br />Peixian Chen, Mengdan Zhang, Yunhang Shen, Kekai Sheng, Yuting Gao, Xing Sun, **Ke Li\***, Chunhua Shen.<br />European Conference on Computer Vision (**ECCV**), 2022<br />[Paper](https://arxiv.org/abs/2206.06829), [Code](https://github.com/Pealing/DFFT)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/Pealing/DFFT.svg" alt="GitHub stars" title="" /> |
| **ARM: Any-Time Super-Resolution Method**<br />Bohong Chen, Mingbao Lin, Kekai Sheng, Mengdan Zhang, Peixian Chen, **Ke Li**, Liujuan Cao, Rongrong Ji.<br />European Conference on Computer Vision (**ECCV**), 2022<br />[Paper](https://arxiv.org/abs/2203.10812), [Code](https://github.com/chenbong/ARM-Net)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/chenbong/ARM-Net.svg" alt="GitHub stars" title="" /> |
| **Self-supervised Models are Good Teaching Assistants for Vision Transformers**<br />Haiyan Wu, Yuting Gao, Yinqi Zhang, Shaohui Lin, Yuan Xie, Xing Sun, **Ke Li** .<br />International Conference on Machine Learning (**ICML**), 2022<br />[Paper](https://proceedings.mlr.press/v162/wu22c.html) |
| **Training-free Transformer Architecture Search**<br />Qinqin Zhou, Kekai Sheng, Xiawu Zheng, **Ke Li**, Xing Sun, Yonghong Tian, Jie Chen, Rongrong Ji .<br />Computer Vision and Pattern Recognition (**CVPR, Oral**), 2022<br />[Paper](https://arxiv.org/abs/2203.12217), [Code](https://github.com/decemberzhou/TF_TAS)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/decemberzhou/TF_TAS.svg" alt="GitHub stars" title="" /> |
| **Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer**<br />Yifan Xu, Zhijie Zhang, Mengdan Zhang, Kekai Sheng, **Ke Li**, Weiming Dong, Liqing Zhang, Changsheng Xu, Xing Sun.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2022<br />[Paper](https://arxiv.org/abs/2108.01390), [Code](https://github.com/YifanXu74/Evo-ViT)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/YifanXu74/Evo-ViT.svg" alt="GitHub stars" title="" /> |
| **Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning**<br />Jinpeng Wang, Yuting Gao, **Ke Li**, Yiqi Lin, Andy J Ma, Xing Sun.<br />Computer Vision and Pattern Recognition (**CVPR**), 2021<br />[Paper](https://arxiv.org/abs/2009.05769), [Code](https://github.com/FingerRec/BE)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/FingerRec/BE.svg" alt="GitHub stars" title="" /> |
| **Architecture Disentanglement for Deep Neural Networks**<br />Jie Hu, Liujuan Cao, Qixiang Ye, Tong Tong, ShengChuan Zhang, **Ke Li**, Feiyue Huang, Rongrong Ji, Ling Shao.<br />International Conference on Computer Vision (**ICCV, Oral**), 2021<br />[Paper](https://arxiv.org/abs/2003.13268), [Code](https://github.com/hujiecpp/NAD)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/hujiecpp/NAD.svg" alt="GitHub stars" title="" /> |
| **Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion**<br />Jinpeng Wang, Yuting Gao, **Ke Li**, Xinyang Jiang, Xiaowei Guo, Rongrong Ji, Xing Sun.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2021<br />[Paper](https://arxiv.org/abs/2009.05757), [Code](https://github.com/FingerRec/DSM-decoupling-scene-motion)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/FingerRec/DSM-decoupling-scene-motion.svg" alt="GitHub stars" title="" /> |
| **One for More: Selecting Generalizable Samples for Generalizable ReID Model**<br />Enwei Zhang, Xinyang Jiang, Hao Cheng, Ancong Wu, Fufu Yu, **Ke Li**, Xiaowei Guo, Feng Zheng, Wei-Shi Zheng, Xing Sun.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2021<br />[Paper](https://arxiv.org/abs/2012.05475) |
| **Pruning Filter in Filter**<br />Fanxu Meng, Hao Cheng, **Ke Li**, Huixiang Luo, Xiaowei Guo, Guangming Lu, Xing Sun.<br />Advances in Neural Information Processing Systems (**NeurIPS**), 2020<br />[Paper](https://arxiv.org/abs/2009.14410), [Code](https://github.com/fxmeng/Pruning-Filter-in-Filter)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/fxmeng/Pruning-Filter-in-Filter.svg" alt="GitHub stars" title="" /> |
| **Filter Grafting for Deep Neural Networks**<br />Fanxu Meng, Hao Cheng, **Ke Li**, Zhixin Xu, Rongrong Ji, Xing Sun, Gaungming Lu.<br />Computer Vision and Pattern Recognition (**CVPR**), 2020<br />[Paper](https://arxiv.org/abs/2001.05868), [Code](https://github.com/fxmeng/filter-grafting)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/fxmeng/filter-grafting.svg" alt="GitHub stars" title="" /> |
| **Asymmetric Co-Teaching for Unsupervised Cross Domain Person Re-Identification**<br />Fengxiang Yang, **Ke Li**, Zhun Zhong, Zhiming Luo, Xing Sun, Hao Cheng, Xiaowei Guo, Feiyue Huang, Rongrong Ji, Shaozi Li.<br />Proceedings of the AAAI Conference on Artificial Intelligence (**AAAI**), 2020.<br />[Paper](https://arxiv.org/abs/1912.01349), [Code](https://github.com/FlyingRoastDuck/ACT_AAAI20)<img style="border: 0px;padding: 0px;border-radius: 5px;" src="https://img.shields.io/github/stars/FlyingRoastDuck/ACT_AAAI20.svg" alt="GitHub stars" title="" /> |
| **Semi-Supervised Adversarial Monocular Depth Estimation**<br />Rongrong Ji, **Ke Li\***, Yan Wang, Feng Guo, Xiaowei Guo, Yongjian Wu, Feiyue Huang, and Jiebo Luo.<br />IEEE Transactions on Pattern Analysis and Machine Intelligence (**TPAMI**), 2019.<br />[Paper](https://arxiv.org/abs/1908.02126) |


## More About

*   Born in Zhengzhou. Now live in Shanghai.
*	Aside from my academic experience in computer science, I hold a B.A. degree in English ([TEM-8 certified](https://en.wikipedia.org/wiki/College_English_Test)) and gained practical experience teaching writing skills part-time at [New Oriental](http://www.neworiental.org/english/) from 2011 to 2014.
